<!-- build time:Sat Jul 19 2025 01:14:40 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.jpg"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><link rel="mask-icon" href="/images/avatar.jpg" color=""><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="7QiG8wJPa5_9Ca0Y8hlhT0rJtNqEekDbao8u-zvq7zA"><meta name="msvalidate.01" content="9A952D9AAB23A5CE98B20FC76E335FA6"><meta name="yandex-verification" content="cb2a7fddf83f1d59"><link rel="alternate" type="application/rss+xml" title="taf.fyi" href="https://taf.fyi/rss.xml"><link rel="alternate" type="application/atom+xml" title="taf.fyi" href="https://taf.fyi/atom.xml"><link rel="alternate" type="application/json" title="taf.fyi" href="https://taf.fyi/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7Cconsolas:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.6"><meta name="keywords" content="DevOps"><link rel="canonical" href="https://taf.fyi/cs/devops/BDplatforms/"><title>大数据平台 All in One 搭建记录 - DevOps - 计算机科学</title><script src="https://unpkg.com/typed.js@2.1.0/dist/typed.umd.js" async></script><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">大数据平台 All in One 搭建记录</h1><div class="meta"><span class="item" title="Created: 2025-05-07 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">Posted on</span> <time itemprop="dateCreated datePublished" datetime="2025-05-07T00:00:00+08:00">2025-05-07</time> </span><span class="item" title="Symbols count in article"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">Symbols count in article</span> <span>8.5k</span> <span class="text">words</span> </span><span class="item" title="Reading time"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">Reading time</span> <span>8 mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">taf.fyi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><img src="/assets/cs/devops/DBplatforms/apache.svg"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">Home</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/cs/" itemprop="item" rel="index" title="In 计算机科学"><span itemprop="name">计算机科学</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/cs/devops/" itemprop="item" rel="index" title="In DevOps"><span itemprop="name">DevOps</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="en"><link itemprop="mainEntityOfPage" href="https://taf.fyi/cs/devops/BDplatforms/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="fuuzen"><meta itemprop="description" content="taf.fyi, fuuzen 的个人主页 taf.fyi"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="taf.fyi"></span><div class="body md" itemprop="articleBody"><p>安装 <span class="exturl" data-url="aHR0cHM6Ly9jd2lraS5hcGFjaGUub3JnL2NvbmZsdWVuY2UvZGlzcGxheS9IQURPT1AvSGFkb29wK0phdmErVmVyc2lvbnM=">兼容版本的 Java</span>，我这里使用 Ubuntu 24.02，直接使用 apt 安装 Java 8 ：</p><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> openjdk-8-jre</pre></td></tr></table></figure><p>通过 <code>which java</code> ，查看软链接，找到 Java 的实际安装目录，在我这里为 <code>/usr/lib/jvm/java-8-openjdk-amd64</code> 。</p><p>下载 <span class="exturl" data-url="aHR0cHM6Ly93d3cuYXBhY2hlLm9yZy9keW4vY2xvc2VyLmNnaS9oYWRvb3AvY29tbW9uLw==">Hadoop</span>，我这里选择下载 <code>hadoop-stable</code> 的为 <code>hadoop-3.4.1</code> 。直接 <code>wget</code> 下载然后 <code>tar -zxvf</code> 解压。我下载时国内网速太慢，挂了梯子下载然后 <code>scp</code> 分发。</p><p>新建 <code>/etc/profile.d/hadoop.sh</code> 来配置基础环境变量，指定为上面的两个安装路径：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/lib/jvm/java-8-openjdk-amd64</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/home/ubuntu/hadoop-3.4.1</pre></td></tr></table></figure><h2 id="hadoop"><a class="anchor" href="#hadoop">#</a> Hadoop</h2><pre><code class="language-shel">[ubuntu@&#123;server&#125; ~]# cd /opt
[ubuntu@&#123;server&#125; /opt]# sudo tar xzf /home/ubuntu/hadoop-3.4.1.tar.gz
[ubuntu@&#123;server&#125; /opt]# sudo ln -s hadoop-3.4.1/ hadoop
[ubuntu@&#123;server&#125; /opt]# sudo chown -R ubuntu:ubuntu hadoop
[ubuntu@&#123;server&#125; /opt]# sudo chown -R ubuntu:ubuntu hadoop-3.4.1

[ubuntu@&#123;server&#125; /]# sudo mkdir data
[ubuntu@&#123;server&#125; /]# cd /data
[ubuntu@&#123;server&#125; /data]# sudo mkdir hadoop
[ubuntu@&#123;server&#125; /data]# sudo chown -R ubuntu:ubuntu hadoop
[ubuntu@&#123;server&#125; /data/hadoop]# cd hadoop
[ubuntu@&#123;server&#125; /data/hadoop]# mkdir data
[ubuntu@&#123;server&#125; /data/hadoop]# mkdir name
[ubuntu@&#123;server&#125; /data/hadoop]# mkdir pid
[ubuntu@&#123;server&#125; /data/hadoop]# mkdir tmp
</code></pre><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">[</span>ubuntu@master ~<span class="token punctuation">]</span><span class="token comment"># cd /opt/hadoop/etc/hadoop</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/hadoop/etc/hadoop<span class="token punctuation">]</span><span class="token comment"># vim core-site.xml</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># Add these elements:</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">## Do not forget to change the tmp directory</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>fs.defaultFS<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>hdfs://<span class="token punctuation">&#123;</span>master<span class="token punctuation">&#125;</span>:900<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="8"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="9"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>hadoop.tmp.dir<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>/data/hadoop/tmp<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="12"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/hadoop/etc/hadoop<span class="token punctuation">]</span><span class="token comment"># vim hadoop-env.sh</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token comment"># Add these commands:</span></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token comment">## Do not forget to change the PID directory</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/lib/jvm/java-8-openjdk-amd64</pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_PID_DIR</span><span class="token operator">=</span>/data/hadoop/pid</pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/hadoop/etc/hadoop<span class="token punctuation">]</span><span class="token comment"># vim hdfs-site.xml</span></pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token comment"># Add these elements:</span></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token comment">## dfs.replication property specifies replication factor, you may want to change it. I prefer replication factor of two for small clusters.</span></pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token comment">## Do not forget to change the data directory</span></pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token comment">## Do not forget to change the name directory</span></pre></td></tr><tr><td data-num="23"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs.namenode.http-address<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token punctuation">&#123;</span>master<span class="token punctuation">&#125;</span>:900<span class="token operator"><span class="token file-descriptor important">1</span>&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="26"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="27"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="28"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs.namenode.secondary.http-address<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token punctuation">&#123;</span>master<span class="token punctuation">&#125;</span>:900<span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="30"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="31"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="32"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs.webhdfs.enabled<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>true<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="34"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="35"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs.replication<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="37"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="38"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="39"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="40"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs.data.dir<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>/data/hadoop/data<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="42"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="43"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="44"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs.name.dir<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="45"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>/data/hadoop/name<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="46"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="47"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>dfs.permission<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="49"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>false<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="50"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="51"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/hadoop/etc/hadoop<span class="token punctuation">]</span><span class="token comment"># vim mapred-site.xml</span></pre></td></tr><tr><td data-num="52"></td><td><pre><span class="token comment"># Add these elements:</span></pre></td></tr><tr><td data-num="53"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="54"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce.framework.name<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="55"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>yarn<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="56"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="57"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="58"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce.application.classpath<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="59"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token variable">$HADOOP_MAPRED_HOME</span>/share/hadoop/mapreduce/*:<span class="token variable">$HADOOP_MAPRED_HOME</span>/share/hadoop/mapreduce/lib/*<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="60"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="61"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="62"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>mapred.job.tracker<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="63"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token punctuation">&#123;</span>master<span class="token punctuation">&#125;</span>:5431<span class="token operator"><span class="token file-descriptor important">1</span>&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="64"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="65"></td><td><pre><span class="token comment"># The host and port that the MapReduce job tracker runs at.  If "local", then jobs are run in-process as a single map and reduce task.</span></pre></td></tr><tr><td data-num="66"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/hadoop/etc/hadoop<span class="token punctuation">]</span><span class="token comment"># vim workers</span></pre></td></tr><tr><td data-num="67"></td><td><pre><span class="token comment"># Add the names of all workers</span></pre></td></tr><tr><td data-num="68"></td><td><pre>cpf-2</pre></td></tr><tr><td data-num="69"></td><td><pre>cpf-3</pre></td></tr><tr><td data-num="70"></td><td><pre>cpf-4</pre></td></tr><tr><td data-num="71"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/hadoop/etc/hadoop<span class="token punctuation">]</span><span class="token comment"># vim yarn-site.xml</span></pre></td></tr><tr><td data-num="72"></td><td><pre><span class="token comment"># Add these lines</span></pre></td></tr><tr><td data-num="73"></td><td><pre><span class="token comment">## You may want to change the max-disk-utilization-per-disk-percentage.</span></pre></td></tr><tr><td data-num="74"></td><td><pre><span class="token comment">## Notice that the value of "yarn.nodemanager.hostname" property is &#123;worker&#125;. We leave it for now, and will change it later</span></pre></td></tr><tr><td data-num="75"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="76"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn.nodemanager.aux-services<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="77"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>mapreduce_shuffle<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="78"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="79"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="80"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn.nodemanager.env-whitelist<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="81"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="82"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="83"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="84"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="85"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token number">9</span><span class="token operator"><span class="token file-descriptor important">5</span>&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="86"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="87"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="88"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn.resourcemanager.hostname<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="89"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token punctuation">&#123;</span>master<span class="token punctuation">&#125;</span><span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="90"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr><tr><td data-num="91"></td><td><pre>  <span class="token operator">&lt;</span>property<span class="token operator">></span></pre></td></tr><tr><td data-num="92"></td><td><pre>    <span class="token operator">&lt;</span>name<span class="token operator">></span>yarn.nodemanager.hostname<span class="token operator">&lt;</span>/name<span class="token operator">></span></pre></td></tr><tr><td data-num="93"></td><td><pre>    <span class="token operator">&lt;</span>value<span class="token operator">></span><span class="token punctuation">&#123;</span>worker<span class="token punctuation">&#125;</span><span class="token operator">&lt;</span>/value<span class="token operator">></span></pre></td></tr><tr><td data-num="94"></td><td><pre>  <span class="token operator">&lt;</span>/property<span class="token operator">></span></pre></td></tr></table></figure><p><code>sudo vim /etc/profile.d/hadoop.sh</code></p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># Java</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/lib/jvm/java-8-openjdk-amd64</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># Haddop &amp; YARN</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">PDSH_RCMD_TYPE</span><span class="token operator">=</span>ssh</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/opt/hadoop</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_CONF_DIR</span><span class="token operator">=</span>/opt/hadoop/etc/hadoop</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_MAPRED_HOME</span><span class="token operator">=</span>/opt/hadoop</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_COMMON_HOME</span><span class="token operator">=</span>/opt/hadoop</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HDFS_HOME</span><span class="token operator">=</span>/opt/hadoop</pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_YARN_HOME</span><span class="token operator">=</span>/opt/hadoop</pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>/bin:<span class="token environment constant">$PATH</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_NAMENODE_USER</span><span class="token operator">=</span><span class="token string">"ubuntu"</span></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_DATANODE_USER</span><span class="token operator">=</span><span class="token string">"ubuntu"</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_SECONDARYNAMENODE_USER</span><span class="token operator">=</span><span class="token string">"ubuntu"</span></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">YARN_RESOURCEMANAGER_USER</span><span class="token operator">=</span><span class="token string">"ubuntu"</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">YARN_NODEMANAGER_USER</span><span class="token operator">=</span><span class="token string">"ubuntu"</span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>/lib/native</pre></td></tr></table></figure><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">[</span>ubuntu@master ~<span class="token punctuation">]</span><span class="token comment"># hadoop namenode -format</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span>ubuntu@master ~<span class="token punctuation">]</span><span class="token comment"># /opt/hadoop/sbin/start-dfs.sh</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">[</span>ubuntu@master ~<span class="token punctuation">]</span><span class="token comment"># /opt/hadoop/sbin/start-yarn.sh</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">[</span>ubuntu@master ~<span class="token punctuation">]</span><span class="token comment"># /opt/hadoop/sbin/stop-yarn.sh</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">[</span>ubuntu@master ~<span class="token punctuation">]</span><span class="token comment"># /opt/hadoop/sbin/stop-dfs.sh</span></pre></td></tr></table></figure><p>万一误操作导致 hdfs 文件系统爆了，执行如下：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token shebang important">#!/bin/bash</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token function">rm</span> <span class="token parameter variable">-rf</span> /data/hadoop/data</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token function">rm</span> <span class="token parameter variable">-rf</span> /data/hadoop/name</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token function">rm</span> <span class="token parameter variable">-rf</span> /data/hadoop/pid</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token function">rm</span> <span class="token parameter variable">-rf</span> /data/hadoop/tmp</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/hadoop/data</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/hadoop/name</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/hadoop/pid</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/hadoop/tmp</pre></td></tr></table></figure><h2 id="spark"><a class="anchor" href="#spark">#</a> Spark</h2><pre><code class="language-shel">[ubuntu@&#123;server&#125; ~]# cd /opt
[ubuntu@&#123;server&#125; /opt]# sudo tar xzf /home/ubuntu/spark-3.4.4-bin-hadoop3.tgz
[ubuntu@&#123;server&#125; /opt]# sudo ln -s spark-3.4.4-bin-hadoop3/ spark
[ubuntu@&#123;server&#125; /opt]# sudo chown -R ubuntu:ubuntu spark
[ubuntu@&#123;server&#125; /opt]# sudo chown -R ubuntu:ubuntu spark-3.4.4-bin-hadoop3
</code></pre><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">[</span>ubuntu@<span class="token punctuation">&#123;</span>server<span class="token punctuation">&#125;</span> ~<span class="token punctuation">]</span><span class="token comment"># cd /opt/spark/conf</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span>ubuntu@<span class="token punctuation">&#123;</span>server<span class="token punctuation">&#125;</span> /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># cp /opt/hadoop/etc/hadoop/core-site.xml .</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token punctuation">[</span>ubuntu@<span class="token punctuation">&#123;</span>server<span class="token punctuation">&#125;</span> /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># cp /opt/hadoop/etc/hadoop/hdfs-site.xml .</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token punctuation">[</span>ubuntu@<span class="token punctuation">&#123;</span>server<span class="token punctuation">&#125;</span> /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># cp /opt/hadoop/etc/hadoop/yarn-site.xml .</span></pre></td></tr></table></figure><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># cp workers.template workers</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># vim workers</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># Add the names of all workers</span></pre></td></tr><tr><td data-num="4"></td><td><pre>cpf-2</pre></td></tr><tr><td data-num="5"></td><td><pre>cpf-3</pre></td></tr><tr><td data-num="6"></td><td><pre>cpf-4</pre></td></tr></table></figure><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># cp spark-env.sh.template spark-env.sh</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># vim spark-env.sh</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># Add these lines</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/lib/jvm/java-8-openjdk-amd64</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_HOME</span><span class="token operator">=</span>/opt/spark</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_CONF_DIR</span><span class="token operator">=</span><span class="token variable">$SPARK_HOME</span>/conf</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/opt/hadoop</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_CONF_DIR</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>/etc/hadoop</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">YARN_CONF_DIR</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>/etc/hadoop</pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_WORKER_DIR</span><span class="token operator">=</span>/tmp/spark/work</pre></td></tr></table></figure><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># cp log4j2.properties.template log4j2.properties</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">[</span>ubuntu@master /opt/spark/conf<span class="token punctuation">]</span><span class="token comment"># vim log4j2.properties</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment"># ......</span></pre></td></tr></table></figure><p><code>sudo vim /etc/profile.d/spark.sh</code> 配置 Spark 相关环境变量：</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_HOME</span><span class="token operator">=</span>/opt/spark</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_CONF_DIR</span><span class="token operator">=</span><span class="token variable">$SPARK_HOME</span>/conf</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token variable">$SPARK_HOME</span>/bin:<span class="token environment constant">$PATH</span></pre></td></tr></table></figure><p>上传 Spark 相关 jar 文件到 HDFS：</p><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre>hdfs dfs <span class="token parameter variable">-mkdir</span> <span class="token parameter variable">-p</span> /user/spark/share/lib</pre></td></tr><tr><td data-num="2"></td><td><pre>hadoop fs <span class="token parameter variable">-put</span> /opt/spark/jars/* /user/spark/share/lib/</pre></td></tr></table></figure><p>访问：</p><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment"># HDFS Web UI (namenode)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token function">ssh</span> <span class="token parameter variable">-L</span> <span class="token number">9870</span>:10.10.3.183:9870 openstack@222.200.180.102 <span class="token parameter variable">-N</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment"># HDFS Web UI (secondary namenode)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token function">ssh</span> <span class="token parameter variable">-L</span> <span class="token number">9868</span>:10.10.3.183:9868 openstack@222.200.180.102 <span class="token parameter variable">-N</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment"># YARN Web UI</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token function">ssh</span> <span class="token parameter variable">-L</span> <span class="token number">8088</span>:10.10.3.183:8088 openstack@222.200.180.102 <span class="token parameter variable">-N</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token function">ssh</span> <span class="token parameter variable">-L</span> <span class="token number">8042</span>:10.10.1.96:8042 openstack@222.200.180.102 <span class="token parameter variable">-N</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token function">ssh</span> <span class="token parameter variable">-L</span> <span class="token number">8043</span>:10.10.3.222:8042 openstack@222.200.180.102 <span class="token parameter variable">-N</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token function">ssh</span> <span class="token parameter variable">-L</span> <span class="token number">8044</span>:10.10.0.176:8042 openstack@222.200.180.102 <span class="token parameter variable">-N</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment"># zipkin</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token function">ssh</span> <span class="token parameter variable">-L</span> <span class="token number">9411</span>:10.10.3.183:9411 openstack@222.200.180.102 <span class="token parameter variable">-N</span></pre></td></tr></table></figure><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>Host hadoop-tunnel</pre></td></tr><tr><td data-num="2"></td><td><pre>  HostName <span class="token number">222.200</span>.180.102</pre></td></tr><tr><td data-num="3"></td><td><pre>  User openstack</pre></td></tr><tr><td data-num="4"></td><td><pre>  <span class="token comment"># HDFS Web UI (namenode)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  LocalForward <span class="token number">9868</span> <span class="token number">10.10</span>.3.183:9868</pre></td></tr><tr><td data-num="6"></td><td><pre>  <span class="token comment"># HDFS Web UI (secondary namenode)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>  LocalForward <span class="token number">9870</span> <span class="token number">10.10</span>.3.183:9870</pre></td></tr><tr><td data-num="8"></td><td><pre>  <span class="token comment"># YARN Web UI</span></pre></td></tr><tr><td data-num="9"></td><td><pre>  LocalForward <span class="token number">8088</span> <span class="token number">10.10</span>.3.183:8088</pre></td></tr><tr><td data-num="10"></td><td><pre>  LocalForward <span class="token number">8042</span> <span class="token number">10.10</span>.1.96:8042</pre></td></tr><tr><td data-num="11"></td><td><pre>  LocalForward <span class="token number">8043</span> <span class="token number">10.10</span>.3.222:8042</pre></td></tr><tr><td data-num="12"></td><td><pre>  LocalForward <span class="token number">8044</span> <span class="token number">10.10</span>.0.176:8042</pre></td></tr><tr><td data-num="13"></td><td><pre>  <span class="token comment"># zipkin</span></pre></td></tr><tr><td data-num="14"></td><td><pre>  LocalForward <span class="token number">9411</span> <span class="token number">10.10</span>.3.183:9411</pre></td></tr></table></figure><p>如何 submit 一个任务:</p><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre>spark-submit <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token parameter variable">--master</span> <span class="token function">yarn</span> <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="3"></td><td><pre>  --deploy-mode cluster <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="4"></td><td><pre>  <span class="token parameter variable">--name</span> test01 <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  test.py</pre></td></tr></table></figure><p>python 测试：</p><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>spark <span class="token operator">=</span> SparkSession\</pre></td></tr><tr><td data-num="4"></td><td><pre>        <span class="token punctuation">.</span>builder\</pre></td></tr><tr><td data-num="5"></td><td><pre>        <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.hadoop.fs.defaultFS"</span><span class="token punctuation">,</span> <span class="token string">"hdfs://cpf-1:9000"</span><span class="token punctuation">)</span>\</pre></td></tr><tr><td data-num="6"></td><td><pre>        <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"test01"</span><span class="token punctuation">)</span>\</pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">def</span> <span class="token function">get_python_version</span><span class="token punctuation">(</span>_<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="10"></td><td><pre>  <span class="token keyword">import</span> sys</pre></td></tr><tr><td data-num="11"></td><td><pre>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Python version:"</span><span class="token punctuation">,</span> sys<span class="token punctuation">.</span>version<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token keyword">def</span> <span class="token function">get_packages</span><span class="token punctuation">(</span>_<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="14"></td><td><pre>  <span class="token keyword">import</span> pkg_resources</pre></td></tr><tr><td data-num="15"></td><td><pre>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">&#123;</span>pkg<span class="token punctuation">.</span>key<span class="token punctuation">:</span> pkg<span class="token punctuation">.</span>version <span class="token keyword">for</span> pkg <span class="token keyword">in</span> pkg_resources<span class="token punctuation">.</span>working_set<span class="token punctuation">&#125;</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token comment"># Driver 端的 Python 版本</span></pre></td></tr><tr><td data-num="18"></td><td><pre>get_python_version<span class="token punctuation">(</span><span class="token number">114</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token comment"># Executor 端的 Python 版本</span></pre></td></tr><tr><td data-num="21"></td><td><pre>spark<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>get_python_version<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre><span class="token comment"># 列出所有 Driver 端的包名</span></pre></td></tr><tr><td data-num="24"></td><td><pre>get_packages<span class="token punctuation">(</span><span class="token number">514</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre><span class="token comment"># 列出所有 Executor 端的包名</span></pre></td></tr><tr><td data-num="27"></td><td><pre>spark<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>get_packages<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight shell"><figcaption data-lang="Bash"></figcaption><table><tr><td data-num="1"></td><td><pre>spark-submit <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token parameter variable">--master</span> <span class="token function">yarn</span> <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="3"></td><td><pre>  --deploy-mode cluster <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="4"></td><td><pre>  <span class="token parameter variable">--jars</span> spot-complete-3.5_2.12-0.1.0.jar <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  <span class="token parameter variable">--conf</span> <span class="token assign-left variable">spark.extraListeners</span><span class="token operator">=</span>com.xebia.data.spot.TelemetrySparkListener <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="6"></td><td><pre>  <span class="token parameter variable">--conf</span> <span class="token assign-left variable">spark.otel.traces.exporter</span><span class="token operator">=</span>zipkin <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="7"></td><td><pre>  <span class="token parameter variable">--conf</span> <span class="token assign-left variable">spark.exporter.zipkin.endpoint</span><span class="token operator">=</span>http://localhost:9411/api/v2/spans <span class="token punctuation">\</span></pre></td></tr><tr><td data-num="8"></td><td><pre>  test.py</pre></td></tr></table></figure><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css"><div class="tags"><a href="/tags/DevOps/" rel="tag"><i class="ic i-tag"></i> DevOps</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">Edited on</span> <time title="Modified: 2025-07-08 23:41:16" itemprop="dateModified" datetime="2025-07-08T23:41:16+08:00">2025-07-08</time> </span><span id="cs/devops/BDplatforms/" data-flag-title="大数据平台 All in One 搭建记录" title="Views"><span class="icon"><i class="ic i-eye"></i> </span><span class="text" id="busuanzi_container_page_pv">Views <span id="busuanzi_value_page_pv"></span> times</span></span></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>fuuzen</li><li class="link"><strong>Post link: </strong><a href="https://taf.fyi/cs/devops/BDplatforms/" title="大数据平台 All in One 搭建记录">https://taf.fyi/cs/devops/BDplatforms/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.</li></ul></div></footer></article></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop"><span class="toc-number">1.</span> <span class="toc-text">Hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#spark"><span class="toc-number">2.</span> <span class="toc-text">Spark</span></a></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/cs/devops/acme/" rel="bookmark" title="acme.sh插件">acme.sh插件</a></li><li><a href="/cs/devops/overleaf/" rel="bookmark" title="OverLeaf自建记录">OverLeaf自建记录</a></li><li class="active"><a href="/cs/devops/BDplatforms/" rel="bookmark" title="大数据平台 All in One 搭建记录">大数据平台 All in One 搭建记录</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="fuuzen" data-src="/images/avatar.jpg"><p class="name" itemprop="name">fuuzen</p><div class="description" itemprop="description">fuuzen 的个人主页 taf.fyi</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">23</span> <span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">7</span> <span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">4</span> <span class="name">tags</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL2Z1dXplbg==" title="https:&#x2F;&#x2F;github.com&#x2F;fuuzen"><i class="ic i-github"></i></span> <span class="exturl item telegram" data-url="aHR0cHM6Ly90Lm1lL2Z1dXNlbl9ub19wYXJ0eQ==" title="https:&#x2F;&#x2F;t.me&#x2F;fuusen_no_party"><i class="ic i-paper-plane"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTE3NzMxNDU3NTU=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;1773145755"><i class="ic i-cloud-music"></i></span> <span class="exturl item bilibili" data-url="aHR0cHM6Ly9zcGFjZS5iaWxpYmlsaS5jb20vNTE0OTI3MjkxLw==" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;514927291&#x2F;"><i class="ic i-bilibili"></i></span> <a href="/rss.xml" title="&#x2F;rss.xml" class="item rss"><i class="ic i-rss"></i></a></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>About</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>Posts</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a></li></ul></li><li class="item"><a href="/notebook/" rel="section"><i class="ic i-pen"></i>Notebook</a></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>Friends</a></li><li class="item"><a href="/acgn/" rel="section"><i class="ic i-magic"></i>ACGN</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/cs/db/mini-oceanbase/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/acgn/eustia/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"></div><div class="status"><div class="copyright">&copy; 2023 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">fuuzen @ taf.fyi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-eye"></i> </span><span class="text" id="busuanzi_container_site_pv"><span id="busuanzi_value_site_pv"></span> views </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-heart"></i> </span><span class="text" id="busuanzi_container_site_uv"><span id="busuanzi_value_site_uv"></span> visitors </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="Symbols count total">165k words</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="Reading time total">2:30</span></div><div class="powered-by">Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"cs/devops/BDplatforms/",favicon:{show:"Ciallo～(∠・ω< )⌒★!",hide:"Signaled Out"},search:{placeholder:"Search for Posts",empty:"We didn't find any results for the search: ${query}",stats:"${hits} results found in ${time} ms"},copy_tex:!0,katex:!0,fancybox:!0,copyright:'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="//fastly.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.6"></script></body></html><!-- rebuild by hrmmi -->